# ==========================================================
# stream2segment config file to tune the download subroutine
# ==========================================================

# {{ YAML_WARN }}

# =================
# POGRAM PARAMETERS
# =================

# Database url where to save data (currently supported are sqlite and postgresql).
# If sqlite, just write the path to your local file
# prefixed with 'sqlite:///' (e.g., 'sqlite:////home/myfolder/db.sqlite'): non-absolute
# paths will be relative to the config file they are written in.
# If non-sqlite, the syntax is:
# dialect+driver://username:password@host:port/database
# E.g.: 'postgresql://smith:Hw_6,@mymachine.example.org/mydb'
# (for info see: http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls)
dburl: 'sqlite:////path/to/my/db.sqlite'

# Try to dowonload again already saved segments with no waveform data because not found
# in the response. This is NOT the case when the server returns no data with an appropriate
# 'No Content' message, but when a successful response (usually '200: OK') does not contain
# the expected segment data. E.g., a multi-segment request returns some but not all requested
# segments.
retry_seg_not_found: true
# Try to dowonload again already saved segments with no waveform data because of a
# general url error (e.g., no internet connection, timeout, ...)
retry_url_err: true
# Try to dowonload again already saved segments with no waveform data because the response was
# malformed, i.e. not readable as MiniSeed
retry_mseed_err: false
# Try to dowonload again already saved segments with no waveform data because of a client error
# (response code in [400,499])
retry_client_err: false
# Try to dowonload again already saved segments with no waveform data because of a server error
# (response code in [500,599])
retry_server_err: true
# Try to download again already saved segments with no waveform data because the response data
# was completely outside the requested time span (see 'timespan' for details)
retry_timespan_err: true

# Update segments metadata, i.e. overwrite the data of already saved stations and channels.
# Metadata include the station inventories (see 'inventory' for details).
# This parameter does not affect new stations and channels, which will be saved on the db anyway
update_metadata: false

# Download station inventories (xml format):
# inventories will be downloaded and saved on the db for all stations that have saved segments
# with data. If the metadata should not be updated (see 'update_metadata') already saved inventories
# will not be downloaded again. You can always fetch and save inventories later during processing,
# if required
inventory: true

# this parameter controls how to access restricted data. It can be:
# - in case of eida (see "dataws" parameter) a single string pointing to a token file for
#   restricted data authorization
#   (https://geofon.gfz-potsdam.de/waveform/archive/auth/auth-overview.php)
# - a list of two strings denoting username and password
# when null, or the empty string, data services will be accessed unauthenticated, thus only
# open (unrestricted) waveform data will be downloaded
restricted_data: "path to myfile"

# =====================
# DATA QUERY PARAMETERS
# =====================

# Limit to events (and datacenters) on or after the specified start time. Specify a date or
# date-time in iso-format or an integer >=0 to denote the number of days before today at midnight.
# Example: start=1 and end=0 => fetch events occurred yesterday.
# Implementation details: 'starttime' is also a valid name for this parameter
start: 2006-01-01T00:00:00
# Limit to events (and datacenters) on or before the specified end time. Specify a date or
# date-time in iso-format or an integer >=0 to denote the number of days before today at midnight.
# Example: start=1 and end=0 => fetch events occurred yesterday.
# Implementation details: 'endtime' is also a valid name for this parameter
end: 2016-12-25T00:00:00

# the event web service to use (url)
eventws: 'http://seismicportal.eu/fdsnws/event/1/query'

# a dict of fdns ws arguments for the eventws query. All values are permitted except 'format',
# 'start' and 'end' (the latter are taken from the values of the relative config parameters
# specified above)
eventws_query_args:
  minmag: 3.0
  minlat: 47.0
  maxlat: 57.0
  minlon: 4.0
  maxlon: 17.0
  mindepth: 1
  maxdepth: 50

# data-select web service to use (url). It should be FDSN compliant, so that the relative
# station web service url can be retrieved automatically. You can also type two special values,
# "iris" (shortcut for: https://service.iris.edu/fdsnws/dataselect/1/query) or "eida"
# (which will automatically fetch data from the urls of all EIDA datacenters).
# Implementation details: If the station web service(s) did not return data
# (e.g., connection problems), then the requested stations and channales will be fetched from the
# database. In this case, if the database is empty the download process will stop with an error
# message.
dataws: 'eida'

# Limit the search to the specified channels.
# (if missing, it's value defaults to '*', i.e. accept all channels)
# Wildcards '?' and '*' are recognized (https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf),
# as well as the operator '!' placed as first character to indicate logical NOT.
# Example: "!B*,BBB" accepts all channels NOT starting with "B" OR the channel "BBB"
# Implementation details: 'cha' or 'channels' are also valid names for the parameter. You can
# also specify a list/array of strings in yaml format instead of comma-separated strings.
# E.g., these are quivalent:
# channels: "A,B"
# cha: [ "A" , "B" ]
# channel:
#  - "A"
#  - "B"
channel:
 - "HH?"
 - 'HN?'
 - 'HL?'
 
# Limit the search to the specified networks (see 'channel' parameter above for details).
# Implementation details: 'net' or 'networks' are also valid names for the parameter.
# By default the line below is commented, meaning that all networks are accepted:
# network: '*'

# Limit the search to the specified stations (see 'channel' parameter above for details).
# Implementation details: 'sta' or 'stations' are also valid names for the parameter.
# By default the line below is commented, meaning that all stations are accepted:
# station: '*'

# Limit the search to the specified locations (see 'channel' parameter above for details).
# Implementation details: 'loc' or 'locations' are also valid names for the parameter.
# By default the line below is commented, meaning that all locations are accepted:
# location: '*'

# Limit the search to channels with at least the following sample rate (in Hz).
# The relative segments will *mot likely* (but not always) match the channel sample rate.
# Set to 0 or negative number to ignore the sampling rate
min_sample_rate: 60

# search radius: for each event, stations will be searched within a circular area whose radius
# is a linear function of the event magnitude:
#
#                   |
#     maxmag_radius +                oooooooooooo
#                   |              o
#                   |            o
#                   |          o
#     minmag_radius + oooooooo
#                   |
#                   ---------+-------+------------
#                         minmag   maxmag
# Edge cases:
# - if minmag_radius == maxmag_radius = R, this is equivalent to a constant function returning
#   always R regardless of the magnitude
# - if minmag_radius != maxmag_radius and minmag == maxmag = M, this function returns
#   minmag_radius for all magnitudes < M, maxmag_radius for all magnitudes > M, and
#   (minmag_radius + maxmag_radius) / 2 for all magnitudes == M
search_radius:
 minmag: 6 # min magnitude
 maxmag: 7 # max magnitude
 minmag_radius: 3 # search radius for min mag (deg)
 maxmag_radius: 3 # search radius for max mag (deg)

# The model to be used to asses the travel times of a wave from
# the event location to each station location. Type a string denoting a file name (absolute path)
# of a custom model created by means of `s2s utils ttcreate` or one of the 4 built-in models
# (all assuming receiver depth=0 for simplicity):
# ak135_ttp+: ak135 model pre-computed for all ttp+ phases (P wave arrivals)
# ak135_tts+: ak135 model pre-computed for all tts+ phases (S wave arrivals)
# iasp91_ttp+: iasp91 model pre-computed for all ttp+ phases (P wave arrivals)
# iasp91_tts+: iasp91 model pre-computed for all tts+ phases (S wave arrivals)
# For each segment, the arrival time (travel
# time + event time) will be the pivot whereby the user sets up the download time window
# (see also 'timespan').
# Implementation details: a model is internally a 2- or 3-dimensional grid
# of pre-computed travel time points coupled with an highly efficient
# algoritm which returns interpolated travel time values. This results in a relevant increase in
# execution speed, with max errors in the order of 0.5 seconds due to interpolation.
traveltimes_model: 'ak135_ttp+'

# The segment's time span (i.e., the data time window to download): specify two positive floats denoting the 
# minutes to account for before and after the calculated arrival time. Note that 3.5 means
# 3 minutes 30 seconds, and that each segment window will be eventually rounded to the nearest
# second to avoid floating point errors when checking for segments to re-download because of a
# changed window.
timespan:
 - 1.0 # start time of the waveform segment to download, in minutes *before* the calculated arrival time.
 - 3.0 # end time of the waveform segment to download, in minutes *after* the calculated arrival time


# ====================================================================================================
# Advanced settings (in principle, you should not care about these unless you know what you are doing)
# ====================================================================================================

advanced_settings:
 # the routing service used to fetch the eida nodes and relative network/stations
 routing_service_url: "http://rz-vm258.gfz-potsdam.de/eidaws/routing/1/query"
 # size (in bytes) of each block of data requested when downloading until no data is available.
 # This setting holds for any kind of data downloaded (event, waveform or station metadata)
 # If 0 or negative, all data will be read in a single call (if 0, it will be converted to -1).
 download_blocksize: 1048576  # = 1024*1024
 # how many parallel threads to start when downloading (one thread per download)
 # If 0 or negative, is automatically set according to the machine CPU
 # (https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor)
 max_thread_workers: 0
 # max time to wait (in seconds) for a single request while downloading stations+channel metadata
 # (`urllib2.urlopen` timeout argument)
 s_timeout: 120
 # If the flag to download station inventories is on (true), max time to wait (in seconds) for a
 # single request while downloading an inventory in xml format (`urllib2.urlopen` timeout argument)
 i_timeout: 60
 # max time to wait (in seconds) for a single request while downloading waveform data
 # (`urllib2.urlopen` timeout argument)
 w_timeout: 60
 # the buffer size used when writing items (stations, segments, events, ...) to database.
 # Increasing this number usually sppeds speed up db IO operations, but increases the potentially
 # unsaved rows in case of errors, as if a row item in the buffer cannot be inserted or updated
 # (e.g., integrity errors), all subsequent buffer items will be also discarded
 db_buf_size: 20
