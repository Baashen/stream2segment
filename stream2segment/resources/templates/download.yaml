# ==========================================================
# stream2segment config file to tune the download subroutine
# ==========================================================

# {{ YAML_WARN }}


# Database URL where to save data (currently supported are SQLite and Postgres).
# We suggest sqlite for small to medium data sizes or enough system RAM (as a rule of
# thumb: less than a million segments, and/or more than 8GB of RAM) and postgres
# otherwise (note that with postgres, the database must have been created beforehand).
# If sqlite, just write the path to your local file prefixed with 'sqlite:///' (e.g.,
# 'sqlite:////home/myfolder/db.sqlite'): non-absolute paths will be relative to the
# config file path.
# If non-sqlite, the syntax is: dialect+driver://username:password@host:port/database
# E.g.: postgresql://smith:Hw_6,@mymachine.example.org/mydb
# (for info see: http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls)
dburl: 'sqlite:///./db.sqlite'

# Limit to events / data centers / station / channels on or after the specified start
# time. Specify an ISO-formatted date or date-time string, or an integer >=0 to denote
# the number of days before today at midnight, e.g., start=1 and end=0 means: fetch
# events occurred yesterday.
# Implementation details: 'start' is also a valid name for this parameter
starttime: 2006-01-01T00:00:00

# Limit to events / data centers / station / channels on or before the specified end
# time. Specify an ISO formatted date or date-time string, or an integer >=0 to denote
# the number of days before today at midnight, e.g., start=1 and end=0 means: fetch
# events occurred yesterday.
# Implementation details: 'end' is also a valid name for this parameter
endtime: 2016-12-25T00:00:00


# =======
# Events: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=14
# =======

# The URL of the event catalog (event web service) or local file path of the events list.
# The events list returned by the URL or in the supplied file must be formatted as
# specified in https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=16
# or in isf format (http://www.isc.ac.uk/standards/isf/download/isf.pdf), although the
# latter has limited support in this program (e.g., comments are not recognized. Use at
# your own risk).
# IMPORTANT: when providing a file, the file name (not the full path) will be used as
# catalog identifier: renaming the file and downloading again on the same database
# will result in the events and their segments being saved twice (unnecessarily).
# Implementation details: 1. Type URLs up to and not including the first query character
# '?' (see example in the default template). 2. You can also type one of the following
# shortcut strings instead of URLs:
# {{ DOWNLOAD_EVENTWS_LIST }}.
eventws: 'http://seismicportal.eu/fdsnws/event/1/query'

# Limit to events with a latitude larger than or equal to the specified minimum.
# This parameter is ignored if missing, null, or 'eventws' is given as file path
# Implementation details: 'minlat' is also a valid name for this parameter
minlatitude: 47.0

# Limit to events with a latitude smaller than or equal to the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
# Implementation details: 'maxlat' is also a valid name for this parameter
maxlatitude: 57.0

# Limit to events with a longitude larger than or equal to the specified minimum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
# Implementation details: 'minlon' is also a valid name for this parameter
minlongitude: 4.0

# Limit to events with a longitude smaller than or equal to the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
# Implementation details: 'maxlon' is also a valid name for this parameter
maxlongitude: 17.0

# Limit to events with depth more than the specified minimum.
# This parameter is ignored if missing, null, or 'eventws' is given as file path
mindepth: 1

# Limit to events with depth less than the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
maxdepth: 50

# Limit to events with a magnitude larger than the specified minimum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
# Implementation details: 'minmag' is also a valid name for this parameter
minmagnitude: 4.0

# Limit to events with a magnitude smaller than the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
# Implementation details: 'maxmag' is also a valid name for this parameter
maxmagnitude: null

# Additional event web search parameters. For info, see
# https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=14
# (parameters with support 'Optional' are not guaranteed to work). Note that the 'format'
# parameter, if missing, will be inferred (in most cases it defaults to 'text').
# Implementation details: The parameter is empty by default, uncomment the lines below
# or insert new ones. Remember that this is a YAML file, pay attention to indentation. 
eventws_params:
  # lat: 47.0
  # lon: 4.0
  # minradius: 17.0
  # maxradius: 21.0


# ====================
# Stations / Channels: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=10
# ====================

# Limit the search to the specified channels (if missing, defaults to '*', i.e.: accept
# all channels). Wildcards '?' and '*' are recognized
# (https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf), as well as the
# operator '!' placed as first character to indicate logical NOT. Example: "!B*,BBB"
# accepts all channels NOT starting with "B" OR the channel "BBB"
# Implementation details: 'cha' or 'channels' are also valid names for the parameter. You
# can also specify a list/array of strings in yaml format instead of comma-separated
# strings. E.g., these are equivalent:
# channels: "A,B"
# cha: [ "A" , "B" ]
# channel:
#  - "A"
#  - "B"
channel:
 - "HH?"
 - 'HN?'
 - 'HL?'
 
# Limit the search to the specified networks (see 'channel' parameter for details).
# Implementation details: 'net' or 'networks' are also valid names for the parameter.
network: '*'

# Limit the search to the specified stations (see 'channel' parameter for details).
# Implementation details: 'sta' or 'stations' are also valid names for the parameter.
station: '*'

# Limit the search to the specified locations (see 'channel' parameter for details).
# Implementation details: 'loc' or 'locations' are also valid names for the parameter.
location: '*'

# Limit the search to channels with at least the following sample rate (in Hz).
# The relative segments will most likely (but not always) match the channel sample rate.
# Set to 0 or negative number to ignore the sampling rate
min_sample_rate: 60

# Update segments metadata, i.e. when fetching stations and channels, save them
# to the database overwriting already saved stations and channels, if present.
# When false, only new stations and channels will be saved to the database.
# On a subsequent download, you can also provide "only" as value (without quotes)
# to update metadata only, skipping events and waveform download: in this case the only
# parameters used will be 'dataws' (to get the station web service(s)) and 'inventory'
# (to optionally re-download and save all station inventories).
update_metadata: false

# Download station inventories (xml format). When true, you can
# control whether or not to overwrite already saved inventories with 'update_metadata'
# (when false, update_metadata should also be false for data consistency).
# Implementation details: inventories will in any case be downloaded and saved on the
# database only for stations that have saved segments with data.
inventory: true

# search radius: defines the criteria for selecting stations around events. It is a dict
# which can have either:
# 1) two arguments ('min', 'max'), to select stations within 'min' and 'max' deggrees
# (endpoints included) from each event location (type min=0 for a circular search area)
# 2) four arguments, to select stations within a circular area whose radius is dependent
# on the event magnitude:
#
#                   |
#     maxmag_radius +                oooooooooooo
#                   |              o
#                   |            o
#                   |          o
#     minmag_radius + oooooooo
#                   |
#                   ---------+-------+------------
#                         minmag   maxmag
# If minmag = maxmag = M, `maxmag_radius` will be used for events with magnitude >= M,
# `minmag_radius` otherwise
search_radius:
 minmag: 6 # min magnitude
 maxmag: 7 # max magnitude
 minmag_radius: 3 # search radius for min mag (deg)
 maxmag_radius: 3 # search radius for max mag (deg)
 # min: 0  # min radius (deg)
 # max: 3  # max radius (deg)


# ========================
# Data (waveform segments) https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=8
# ========================

# List of URLs for downloading waveform data (data web services). All URLs must
# be FDSN-compliant, e.g.: https://service.iris.edu/fdsnws/dataselect/1/query
# You can also type two special values: 1) "iris" (Incorporated Research Institutions for
# Seismology, shortcut for the URL above) or 2) "eida" (European Integrated Data Archive,
# shortcut for the URLs list of all EIDA data centers, or nodes). Being FDSN compliant,
# all URLs are also used to fetch automatically the stations (and channels) necessary for
# the waveforms download.
# IMPORTANT: When providing two (or more) URLs, station conflicts (e.g., the same station
# returned by both URLs) which cannot be resolved will cause the station to be discarded
# (the user will be notified in the log file) and all its available waveforms not to be
# downloaded. The program tries to resolve conflicts with a Routing service (for EIDA
# URLs) or by checking if the station URL is saved on the database from a previous
# download (thus, conflicts involving EIDA nodes have more chances to be resolved).
# Implementation details: If no station /channel could be downloaded (e.g., connection
# problems), then the requested stations and channels will be fetched from the database,
# if non-empty (otherwise the download process will stop with an error message). The EIDA
# routing service is configurable in `advanced_settings`. In the URLs below, If the URL \
# scheme - basically the prefix "http://" or "https://" - is missing, 'http://' will be
# prepended to the URL. An ending '/' or '?' will be removed from the URL, if present).
dataws:
  - 'eida'
  # - 'iris'

# The model to asses the travel time of a wave from the event location to each station
# location. This will be used to get each segment arrival time (travel time + event time)
# and then the final segment window to download (see also `timespan`). Type one of the 4
# built-in precomputed models:
#   ak135_ttp+: ak135 model precomputed for all ttp+ phases (P wave arrivals)
#   ak135_tts+: ak135 model precomputed for all tts+ phases (S wave arrivals)
#   iasp91_ttp+: iasp91 model precomputed for all ttp+ phases (P wave arrivals)
#   iasp91_tts+: iasp91 model precomputed for all tts+ phases (S wave arrivals)
# Implementation details: the models above are optimized for speed in a massive download
# scenario: the median error when compared to real models is in the order of few
# milliseconds (max error reported: 0.5s). You can create your own model via the command
# `s2s utils ttcreate` and use it here by typing its file (absolute) path. However, the
# command is not maintained anymore (there are plans to move it to a new standalone
# program) so use it at your own risk
traveltimes_model: 'ak135_ttp+'

# The segment's time span (i.e., the data time window to download): specify two positive
# floats denoting the minutes to account for before and after the calculated arrival
# time. Note that 3.5 means 3 minutes 30 seconds, and that each segment window will be
# eventually rounded to the nearest second.
# Implementation details: the rounding is necessary to avoid floating point errors when
# checking for segments to re-download because of a changed window.
timespan:
 - 1.0 # start of the waveform segment, in minutes *before* the calculated arrival time.
 - 3.0 # end of the waveform segment, in minutes *after* the calculated arrival time

# Credentials to download restricted data. When null, missing or "", only open waveforms
# will be downloaded. When provided, it can be either a list of two strings (username and
# password), or, for EIDA node(s), a string denoting the path of a token file (for
# info see https://geofon.gfz-potsdam.de/waveform/archive/auth/auth-overview.php)
# IMPORTANT: You SHOULD NOT perform massive, time-consuming downloads when fetching
# restricted data, because 1) it makes no sense: credentials are valid only for the
# organization emitting them (thus there must be only one item in `dataws`) and
# 2) credentials might have an expiration time (e.g., EIDA tokens should have few hours).
# Thus, try narrowing the search (e.g., shorter time bounds, network(s) or station(s) of
# interest only. Have a look also at `max_concurrent_downloads` in `advanced_settings` as
# in this case you might want to improve download efficiency over execution speed).
# Implementation details: restricted segments previously downloaded with no credentials
# (thus, with no waveform data) will be always re-downloaded ignoring all 'retry'
# settings. If you need to provide username and password, remember indentation in YAML
# (see parameter `timespan`). If you provide a token with a non-absolute path, its path
# will be relative to the config file path
restricted_data: ""

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because no data could be found. A typical case is when a request of several
# segments to a server (see `dataws`) got in response only some of them
retry_seg_not_found: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because of a general URL error (e.g., no internet connection, timeout, ...)
retry_url_err: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because the waveform data was malformed, i.e. is not readable as MiniSeed
retry_mseed_err: false

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because of a client (i.e., stream2segment) request error
retry_client_err: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because of a server (see `dataws`) response error
retry_server_err: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because received data was completely outside the requested time window
# (see 'timespan' for details)
retry_timespan_err: true


# =====================================
# Advanced settings (for experts only) 
# =====================================

advanced_settings:
 # Routing service used to fetch the EIDA nodes and relative network/stations
 routing_service_url: "http://www.orfeus-eu.org/eidaws/routing/1/query"
 # Maximum number of concurrent (roughly speaking, simultaneous) downloads allowed. The
 # default (null) means 'set it automatically' (usually between 4 and 8, depending on the
 # number of CPUs in the system), whereas 1 disables concurrency and downloads all data
 # in series (i.e., sequentially).
 # We recommend to leave this parameter to null because it improves significantly the
 # execution speed, and to set it to 1, 2, or any small number of your choice) only in
 # more targeted, less "massive" downloads, e.g.:
 # a) when fetching restricted data (See `restricted_data` parameter)
 # b) when retrying to fetch data from a specific datacenter which reported many download
 #    errors suggesting to lower this parameter, e.g. "Service Unavailable" (code 503)
 #    or "Too Many Requests" (code 429). You can inspect errors in the summary table
 #    printed at the end of each download, or via the command `s2s utils dreport`
 max_concurrent_downloads: null
 # Max time to wait (in seconds) for a single request while downloading events
 e_timeout: 120
 # Max time to wait (in seconds) for a single request while downloading stations+channel
 # metadata
 s_timeout: 120
 # Max time to wait (in seconds) for a single request while downloading an inventory in
 # XML format
 i_timeout: 60
 # Max time to wait (in seconds) for a single request while downloading waveform data
 w_timeout: 30
 # Size (in bytes) of each block of data requested when downloading. It applies to any
 # kind of data (event, waveform or station metadata). If 0, it will be converted to -1.
 # If negative, all data will be always read in a single call and one block.
 download_blocksize: 1048576  # = 1024*1024
 # The buffer size used when writing (inserting or updating) database data, in number of
 # segments. Increasing this number speeds up the download (we experienced performance
 # degradation when it's below the range [30, 50]) but increases the memory consumption.
 # Consider also that a single database error while writing a segment will unfortunately
 # affect all buffer segments, which must all be discarded
 db_buf_size: 100
