###################################################################
# stream2segment config file to tune the functionality.
# IMPORTANT: DO NOT EDIT THIS FILE. COPY THIS FILE AS config.yaml IN THE SAME DIRECTORY AND EDIT THE LATTER
###################################################################

###################
# POGRAM PARAMETERS
###################

# Database url (where data is saved or retrieved, depending on the command issued from the
# terminal).
# If sqlite database, just write the path to your local file
# prefixed with 'sqlite:///' (e.g., 'sqlite:////home/my_folder/db.sqlite'. Non-absolute
# paths will be considered relative to the config file `config.yaml`).
# Otherwise, the syntax is:
# dialect+driver://username:password@host:port/database
# (for info see: http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls)
dburl: 'sqlite:////path/to/my/db.sqlite'

# Set what to do with already saved segments which are empty
# (the datacenter query returned zero bytes) or null (the datacenter query resulted in a connection error).
# Optional: defaults to false if missing
retry: false

# set if station inventories should be downloaded (already downloaded inventories are always skipped)
# inventories are saved for each station and can be used for removing the intrumental response
# Optional: defaults to false if missing
inventory: false


#######################
# DATA QUERY PARAMETERS
#######################

# Limit to events (and datacenters) on or after the specified start time.
# Optional: missing value defaults to yesterday at midnight
start: 2006-01-01T00:00:00
# Limit to events (and datacenters) on or before the specified end time.
# Optional: missing value defaults to today at midnight
end: 2016-12-25T00:00:00

# the event web service
eventws: 'http://seismicportal.eu/fdsnws/event/1/query'

# a dict of fdns ws arguments for the eventws query. All values are permitted except 'format', 'start' 
# and 'end' (the latter are taken from the values of the relative config parameters specified above)
eventws_query_args:
  minmag: 3.0
  minlat: 47.0
  maxlat: 57.0
  minlon: 4.0
  maxlon: 17.0
  mindepth: 1
  maxdepth: 50


# stations will be downloaded with level='channel'. Set here which channels to download. For info see e.g.:
# https://ds.iris.edu/ds/nodes/dmc/tools/data_channels/#???
channels:
 - "HH?"
 # - 'SH?'
 - 'HN?'
 # - 'SN?'
 - 'HL?'
 # - 'SL?'

# Stations time window: specify two positive integers denoting the hours before and after
# each event time, to set the start and end time of the stations search
stimespan:
 - 0 # for each event, limit the search to stations installed at the event time minus this value (in hours)
 - 24 # for each event, limit the search to stations installed at the event time plus this value (in hours)

# search radius: for each event, stations will be searched within a circular area whose radius is a linear function
# of the event magnitude:
#
#                   |
#         maxradius +                oooooooooooo
#                   |              o
#                   |            o
#                   |          o
#         minradius + oooooooo
#                   |
#                   ---------+-------+------------
#                         minmag   maxmag
# NOTE, IMPORTANT:
# if maxradius == minradius=R, this is equivalent to a constant function returning always R regardless of the magnitude
# if minmag == maxmag = M (and maxradius not equal to minradius), this function returns minradius for all magnitudes < M,
#     maxradius for all magnitudes > M, and (minradius+maxradius)/2 for all magnitudes == M
search_radius:
 minmag: 6 # min magnitude
 maxmag: 7 # max magnitude
 minradius: 3 # min radius (deg)
 maxradius: 3 # max radius (deg)
 
# Limit the search to stations with at least min_sample_rate (in Hz).
# The relative segments are *mot likely* (not always) matching the station sample rate.
# Set to 0 or negative number to ignore the sampling rate
min_sample_rate: 60

# Set here the phases to be calculated to asses the travel times of a wave from
# the event location to each station location. The minimum of all travel times will be set as the
# arrival time AT of a specific event at a specific station, and waveform data will be queried to
# the station's datacenter in time a window around AT (see parameter wtimespan below). The more items
# you set here below, the more likely a minimum is found, but the more time is needed to calculate
# all of them.
# NOTE: This parameter is ignored for already downloaded segments, so if you try to adjust the
# arrival time for all downloaded segments you must run a new download from scratch (e.g., specifying a new
# databse output with dburl)
# For info see: https://docs.obspy.org/packages/obspy.taup.html#phase-naming-in-obspy-taup
traveltime_phases: 
 - 'P'
 - 'p'
 - 'Pn'

# Waveform segment time window: specify two positive integers denoting the 
# minutes to account for before and after the calculated arrival time
wtimespan:
 - 1.0 # start time of the waveform segment to download, in minutes *before* the previously calculated arrival time
 - 3.0 # end time of the waveform segment to download, in minutes *after* the previously calculated arrival time


######################################################################################################
# Advanced settings (in principle, you should not care about these unless you know what you are doing)
######################################################################################################

advanced_settings:
 # size of each block of data requested when downloading data (in bytes) until no data is available.
 # If 0 or negative, all data will be read in a single call (if 0, it will be converted to -1).
 download_blocksize: 1048576  # = 1024*1024
 # how many parallel threads to start when downloading (one thread per download)
 # If 0 or negative, is automatically set according to the machine CPU
 # (https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor)
 max_thread_workers: 0
 # max time to wait (in seconds) while downloading stations (`urllib2.urlopen` timeout argument)
 s_timeout: 5
 # If the flag to download station inventories is on, max time to wait (in seconds) while downloading
 #station inventories (`urllib2.urlopen` timeout argument)
 i_timeout: 15
 # max time to wait (in seconds) while downloading waveform data (`urllib2.urlopen` timeout argument)
 w_timeout: 10
 # max number of (url, http...) errors per datacenter, while downloading data only (stations download requires less data and is not affected):
 # after that, all remaining data queries will be discarded (for that datacenter only)
 # Lower values might speed up consistently the download time, at the risk of discarding potentially good data
 # Higher values might slower down consistently the download, reducing the risk of discarding potentually good data
 # Set to zero or negative value to ignore this argument (try to download everything, wait until necessary) 
 w_maxerr_per_dc: -1


###############################################################################
# Classes (label: description) This is used for labelling (annotating via GUI):
# optional argument, you can remove it completely for no labelling
###############################################################################

class_labels:
  Discarded: "Segment which does not fall in any other cathegory (e.g., unknown artifacts, bad formats etcetera)"
  Unknown: "Segment which is either: unlabeled (not annotated) or unclassified"
  Ok: "Segment with no artifact"
  LowS2N: "Segment has a low signal-to-noise ratio"
  MultiEvent: "Segment with overlapping multi-events recorded"
  BadCoda: "Segment with a bad coda (bad decay)"

